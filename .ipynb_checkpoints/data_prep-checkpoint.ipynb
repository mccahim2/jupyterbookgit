{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation for clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For clustering using the k-means method we will need to follow a few steps:\n",
    "* **Standardise the data:** The process of converting an actual range of values into a standard range of values\n",
    "* **Find a Similarity Measure:**\n",
    "* **Interpret Results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('data/all_data.csv')\n",
    "all_data=all_data.drop([\"Unnamed: 0\"], axis=1) # Drop Unnamed: 0 column\n",
    "all_data.head()\n",
    "\n",
    "df = pd.read_csv('data/all_data.csv')\n",
    "df=df.drop([\"Unnamed: 0\"], axis=1) # Drop Unnamed: 0 column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing categorical data entries can be done by One-hot encoding.\n",
    "\n",
    "**One-hot encoding** is a method during data preparation for converting categorical data variables so they can be provided to machine learning algorithims to improve predictions\n",
    "\n",
    "LabelEncoder() is a data manipulation function used to convert categorical data into indicator variables\n",
    "\n",
    ":::{note}\n",
    "Machine learning models require all input and output variables to be numeric\n",
    ":::\n",
    "\n",
    "It is impossible to do k-means clustering on a categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.get_dummies(all_data, columns=[\"Study_Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>No_participants</th>\n",
       "      <th>Amount_won</th>\n",
       "      <th>Amount_lost</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>Study_Type_Fridberg</th>\n",
       "      <th>Study_Type_Horstmann</th>\n",
       "      <th>Study_Type_Kjome</th>\n",
       "      <th>Study_Type_Maia</th>\n",
       "      <th>Study_Type_Premkumar</th>\n",
       "      <th>Study_Type_Steingroever2011</th>\n",
       "      <th>Study_Type_SteingroverInPrep</th>\n",
       "      <th>Study_Type_Wetzels</th>\n",
       "      <th>Study_Type_Wood</th>\n",
       "      <th>Study_Type_Worthy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1150</td>\n",
       "      <td>95</td>\n",
       "      <td>5800</td>\n",
       "      <td>-4650</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-675</td>\n",
       "      <td>95</td>\n",
       "      <td>7250</td>\n",
       "      <td>-7925</td>\n",
       "      <td>24.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-750</td>\n",
       "      <td>95</td>\n",
       "      <td>7100</td>\n",
       "      <td>-7850</td>\n",
       "      <td>12.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-525</td>\n",
       "      <td>95</td>\n",
       "      <td>7000</td>\n",
       "      <td>-7525</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>95</td>\n",
       "      <td>6450</td>\n",
       "      <td>-6350</td>\n",
       "      <td>10.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total  No_participants  Amount_won  Amount_lost     1     2     3     4  \\\n",
       "0   1150               95        5800        -4650  12.0   9.0   3.0  71.0   \n",
       "1   -675               95        7250        -7925  24.0  26.0  12.0  33.0   \n",
       "2   -750               95        7100        -7850  12.0  35.0  10.0  38.0   \n",
       "3   -525               95        7000        -7525  11.0  34.0  12.0  38.0   \n",
       "4    100               95        6450        -6350  10.0  24.0  15.0  46.0   \n",
       "\n",
       "   Study_Type_Fridberg  Study_Type_Horstmann  Study_Type_Kjome  \\\n",
       "0                    1                     0                 0   \n",
       "1                    1                     0                 0   \n",
       "2                    1                     0                 0   \n",
       "3                    1                     0                 0   \n",
       "4                    1                     0                 0   \n",
       "\n",
       "   Study_Type_Maia  Study_Type_Premkumar  Study_Type_Steingroever2011  \\\n",
       "0                0                     0                            0   \n",
       "1                0                     0                            0   \n",
       "2                0                     0                            0   \n",
       "3                0                     0                            0   \n",
       "4                0                     0                            0   \n",
       "\n",
       "   Study_Type_SteingroverInPrep  Study_Type_Wetzels  Study_Type_Wood  \\\n",
       "0                             0                   0                0   \n",
       "1                             0                   0                0   \n",
       "2                             0                   0                0   \n",
       "3                             0                   0                0   \n",
       "4                             0                   0                0   \n",
       "\n",
       "   Study_Type_Worthy  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardising data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for K-means, often it is not sufficient to normalize only mean. One normalizes data equalizing variance along different features as K-means is sensitive to variance in data, and features with larger variance have more emphasis on result. So for K-means, I would recommend using StandardScaler for data preprocessing.\n",
    "\n",
    "Don't forget also that k-means results are sensitive to the order of observations, and it is worth to run algorithm several times, shuffling data in between, averaging resulting clusters and running final evaluations with those averaged clusters centers as starting points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardising data Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=[\"Study_Type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "segmentation_std = scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.04498799, -0.69883592, -1.47141336, ..., -0.26679684,\n",
       "        -0.57423112, -0.2452294 ],\n",
       "       [-0.41434565, -0.69883592, -0.53861339, ..., -0.26679684,\n",
       "        -0.57423112, -0.2452294 ],\n",
       "       [-0.47431826, -0.69883592, -0.63510994, ..., -0.26679684,\n",
       "        -0.57423112, -0.2452294 ],\n",
       "       ...,\n",
       "       [ 1.28487845,  2.29926737,  0.81233829, ...,  3.74817029,\n",
       "        -0.57423112, -0.2452294 ],\n",
       "       [ 1.08496973,  2.29926737,  1.39131758, ...,  3.74817029,\n",
       "        -0.57423112, -0.2452294 ],\n",
       "       [-1.31393487,  2.29926737,  3.32124855, ...,  3.74817029,\n",
       "        -0.57423112, -0.2452294 ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmentation_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standardised data is now stored in an array. I will convert it back to a pandas dataframe,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "      <th>No_participants</th>\n",
       "      <th>Amount_won</th>\n",
       "      <th>Amount_lost</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>Study_Type_Fridberg</th>\n",
       "      <th>Study_Type_Horstmann</th>\n",
       "      <th>Study_Type_Kjome</th>\n",
       "      <th>Study_Type_Maia</th>\n",
       "      <th>Study_Type_Premkumar</th>\n",
       "      <th>Study_Type_Steingroever2011</th>\n",
       "      <th>Study_Type_SteingroverInPrep</th>\n",
       "      <th>Study_Type_Wetzels</th>\n",
       "      <th>Study_Type_Wood</th>\n",
       "      <th>Study_Type_Worthy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.044988</td>\n",
       "      <td>-0.698836</td>\n",
       "      <td>-1.471413</td>\n",
       "      <td>1.525683</td>\n",
       "      <td>-0.477115</td>\n",
       "      <td>-1.386904</td>\n",
       "      <td>-1.089197</td>\n",
       "      <td>2.131753</td>\n",
       "      <td>6.335087</td>\n",
       "      <td>-0.596694</td>\n",
       "      <td>-0.178249</td>\n",
       "      <td>-0.263295</td>\n",
       "      <td>-0.205499</td>\n",
       "      <td>-0.319039</td>\n",
       "      <td>-0.35773</td>\n",
       "      <td>-0.266797</td>\n",
       "      <td>-0.574231</td>\n",
       "      <td>-0.245229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.414346</td>\n",
       "      <td>-0.698836</td>\n",
       "      <td>-0.538613</td>\n",
       "      <td>0.135451</td>\n",
       "      <td>1.024186</td>\n",
       "      <td>-0.420182</td>\n",
       "      <td>-0.668854</td>\n",
       "      <td>0.038743</td>\n",
       "      <td>6.335087</td>\n",
       "      <td>-0.596694</td>\n",
       "      <td>-0.178249</td>\n",
       "      <td>-0.263295</td>\n",
       "      <td>-0.205499</td>\n",
       "      <td>-0.319039</td>\n",
       "      <td>-0.35773</td>\n",
       "      <td>-0.266797</td>\n",
       "      <td>-0.574231</td>\n",
       "      <td>-0.245229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.474318</td>\n",
       "      <td>-0.698836</td>\n",
       "      <td>-0.635110</td>\n",
       "      <td>0.167288</td>\n",
       "      <td>-0.477115</td>\n",
       "      <td>0.091612</td>\n",
       "      <td>-0.762264</td>\n",
       "      <td>0.314139</td>\n",
       "      <td>6.335087</td>\n",
       "      <td>-0.596694</td>\n",
       "      <td>-0.178249</td>\n",
       "      <td>-0.263295</td>\n",
       "      <td>-0.205499</td>\n",
       "      <td>-0.319039</td>\n",
       "      <td>-0.35773</td>\n",
       "      <td>-0.266797</td>\n",
       "      <td>-0.574231</td>\n",
       "      <td>-0.245229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.294400</td>\n",
       "      <td>-0.698836</td>\n",
       "      <td>-0.699441</td>\n",
       "      <td>0.305250</td>\n",
       "      <td>-0.602224</td>\n",
       "      <td>0.034746</td>\n",
       "      <td>-0.668854</td>\n",
       "      <td>0.314139</td>\n",
       "      <td>6.335087</td>\n",
       "      <td>-0.596694</td>\n",
       "      <td>-0.178249</td>\n",
       "      <td>-0.263295</td>\n",
       "      <td>-0.205499</td>\n",
       "      <td>-0.319039</td>\n",
       "      <td>-0.35773</td>\n",
       "      <td>-0.266797</td>\n",
       "      <td>-0.574231</td>\n",
       "      <td>-0.245229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.205371</td>\n",
       "      <td>-0.698836</td>\n",
       "      <td>-1.053262</td>\n",
       "      <td>0.804036</td>\n",
       "      <td>-0.727332</td>\n",
       "      <td>-0.533914</td>\n",
       "      <td>-0.528740</td>\n",
       "      <td>0.754773</td>\n",
       "      <td>6.335087</td>\n",
       "      <td>-0.596694</td>\n",
       "      <td>-0.178249</td>\n",
       "      <td>-0.263295</td>\n",
       "      <td>-0.205499</td>\n",
       "      <td>-0.319039</td>\n",
       "      <td>-0.35773</td>\n",
       "      <td>-0.266797</td>\n",
       "      <td>-0.574231</td>\n",
       "      <td>-0.245229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>0.365298</td>\n",
       "      <td>2.299267</td>\n",
       "      <td>2.613607</td>\n",
       "      <td>-1.530705</td>\n",
       "      <td>1.024186</td>\n",
       "      <td>2.025056</td>\n",
       "      <td>-0.622150</td>\n",
       "      <td>0.644614</td>\n",
       "      <td>-0.157851</td>\n",
       "      <td>-0.596694</td>\n",
       "      <td>-0.178249</td>\n",
       "      <td>-0.263295</td>\n",
       "      <td>-0.205499</td>\n",
       "      <td>-0.319039</td>\n",
       "      <td>-0.35773</td>\n",
       "      <td>3.748170</td>\n",
       "      <td>-0.574231</td>\n",
       "      <td>-0.245229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>1.844623</td>\n",
       "      <td>2.299267</td>\n",
       "      <td>0.780173</td>\n",
       "      <td>0.464437</td>\n",
       "      <td>-1.352875</td>\n",
       "      <td>-0.135852</td>\n",
       "      <td>0.919107</td>\n",
       "      <td>1.966515</td>\n",
       "      <td>-0.157851</td>\n",
       "      <td>-0.596694</td>\n",
       "      <td>-0.178249</td>\n",
       "      <td>-0.263295</td>\n",
       "      <td>-0.205499</td>\n",
       "      <td>-0.319039</td>\n",
       "      <td>-0.35773</td>\n",
       "      <td>3.748170</td>\n",
       "      <td>-0.574231</td>\n",
       "      <td>-0.245229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>1.284878</td>\n",
       "      <td>2.299267</td>\n",
       "      <td>0.812338</td>\n",
       "      <td>0.146063</td>\n",
       "      <td>0.273535</td>\n",
       "      <td>-0.818244</td>\n",
       "      <td>0.498764</td>\n",
       "      <td>2.407149</td>\n",
       "      <td>-0.157851</td>\n",
       "      <td>-0.596694</td>\n",
       "      <td>-0.178249</td>\n",
       "      <td>-0.263295</td>\n",
       "      <td>-0.205499</td>\n",
       "      <td>-0.319039</td>\n",
       "      <td>-0.35773</td>\n",
       "      <td>3.748170</td>\n",
       "      <td>-0.574231</td>\n",
       "      <td>-0.245229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>1.084970</td>\n",
       "      <td>2.299267</td>\n",
       "      <td>1.391318</td>\n",
       "      <td>-0.342110</td>\n",
       "      <td>1.149295</td>\n",
       "      <td>-0.192718</td>\n",
       "      <td>0.825698</td>\n",
       "      <td>1.030169</td>\n",
       "      <td>-0.157851</td>\n",
       "      <td>-0.596694</td>\n",
       "      <td>-0.178249</td>\n",
       "      <td>-0.263295</td>\n",
       "      <td>-0.205499</td>\n",
       "      <td>-0.319039</td>\n",
       "      <td>-0.35773</td>\n",
       "      <td>3.748170</td>\n",
       "      <td>-0.574231</td>\n",
       "      <td>-0.245229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>-1.313935</td>\n",
       "      <td>2.299267</td>\n",
       "      <td>3.321249</td>\n",
       "      <td>-2.889100</td>\n",
       "      <td>-0.602224</td>\n",
       "      <td>4.015366</td>\n",
       "      <td>-0.949083</td>\n",
       "      <td>-0.181574</td>\n",
       "      <td>-0.157851</td>\n",
       "      <td>-0.596694</td>\n",
       "      <td>-0.178249</td>\n",
       "      <td>-0.263295</td>\n",
       "      <td>-0.205499</td>\n",
       "      <td>-0.319039</td>\n",
       "      <td>-0.35773</td>\n",
       "      <td>3.748170</td>\n",
       "      <td>-0.574231</td>\n",
       "      <td>-0.245229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>617 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Total  No_participants  Amount_won  Amount_lost         1         2  \\\n",
       "0    1.044988        -0.698836   -1.471413     1.525683 -0.477115 -1.386904   \n",
       "1   -0.414346        -0.698836   -0.538613     0.135451  1.024186 -0.420182   \n",
       "2   -0.474318        -0.698836   -0.635110     0.167288 -0.477115  0.091612   \n",
       "3   -0.294400        -0.698836   -0.699441     0.305250 -0.602224  0.034746   \n",
       "4    0.205371        -0.698836   -1.053262     0.804036 -0.727332 -0.533914   \n",
       "..        ...              ...         ...          ...       ...       ...   \n",
       "612  0.365298         2.299267    2.613607    -1.530705  1.024186  2.025056   \n",
       "613  1.844623         2.299267    0.780173     0.464437 -1.352875 -0.135852   \n",
       "614  1.284878         2.299267    0.812338     0.146063  0.273535 -0.818244   \n",
       "615  1.084970         2.299267    1.391318    -0.342110  1.149295 -0.192718   \n",
       "616 -1.313935         2.299267    3.321249    -2.889100 -0.602224  4.015366   \n",
       "\n",
       "            3         4  Study_Type_Fridberg  Study_Type_Horstmann  \\\n",
       "0   -1.089197  2.131753             6.335087             -0.596694   \n",
       "1   -0.668854  0.038743             6.335087             -0.596694   \n",
       "2   -0.762264  0.314139             6.335087             -0.596694   \n",
       "3   -0.668854  0.314139             6.335087             -0.596694   \n",
       "4   -0.528740  0.754773             6.335087             -0.596694   \n",
       "..        ...       ...                  ...                   ...   \n",
       "612 -0.622150  0.644614            -0.157851             -0.596694   \n",
       "613  0.919107  1.966515            -0.157851             -0.596694   \n",
       "614  0.498764  2.407149            -0.157851             -0.596694   \n",
       "615  0.825698  1.030169            -0.157851             -0.596694   \n",
       "616 -0.949083 -0.181574            -0.157851             -0.596694   \n",
       "\n",
       "     Study_Type_Kjome  Study_Type_Maia  Study_Type_Premkumar  \\\n",
       "0           -0.178249        -0.263295             -0.205499   \n",
       "1           -0.178249        -0.263295             -0.205499   \n",
       "2           -0.178249        -0.263295             -0.205499   \n",
       "3           -0.178249        -0.263295             -0.205499   \n",
       "4           -0.178249        -0.263295             -0.205499   \n",
       "..                ...              ...                   ...   \n",
       "612         -0.178249        -0.263295             -0.205499   \n",
       "613         -0.178249        -0.263295             -0.205499   \n",
       "614         -0.178249        -0.263295             -0.205499   \n",
       "615         -0.178249        -0.263295             -0.205499   \n",
       "616         -0.178249        -0.263295             -0.205499   \n",
       "\n",
       "     Study_Type_Steingroever2011  Study_Type_SteingroverInPrep  \\\n",
       "0                      -0.319039                      -0.35773   \n",
       "1                      -0.319039                      -0.35773   \n",
       "2                      -0.319039                      -0.35773   \n",
       "3                      -0.319039                      -0.35773   \n",
       "4                      -0.319039                      -0.35773   \n",
       "..                           ...                           ...   \n",
       "612                    -0.319039                      -0.35773   \n",
       "613                    -0.319039                      -0.35773   \n",
       "614                    -0.319039                      -0.35773   \n",
       "615                    -0.319039                      -0.35773   \n",
       "616                    -0.319039                      -0.35773   \n",
       "\n",
       "     Study_Type_Wetzels  Study_Type_Wood  Study_Type_Worthy  \n",
       "0             -0.266797        -0.574231          -0.245229  \n",
       "1             -0.266797        -0.574231          -0.245229  \n",
       "2             -0.266797        -0.574231          -0.245229  \n",
       "3             -0.266797        -0.574231          -0.245229  \n",
       "4             -0.266797        -0.574231          -0.245229  \n",
       "..                  ...              ...                ...  \n",
       "612            3.748170        -0.574231          -0.245229  \n",
       "613            3.748170        -0.574231          -0.245229  \n",
       "614            3.748170        -0.574231          -0.245229  \n",
       "615            3.748170        -0.574231          -0.245229  \n",
       "616            3.748170        -0.574231          -0.245229  \n",
       "\n",
       "[617 rows x 18 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_standard = pd.DataFrame(segmentation_std, columns=['Total', 'No_participants', 'Amount_won', 'Amount_lost', '1', '2', '3', '4', 'Study_Type_Fridberg', 'Study_Type_Horstmann', 'Study_Type_Kjome', 'Study_Type_Maia', 'Study_Type_Premkumar', 'Study_Type_Steingroever2011', 'Study_Type_SteingroverInPrep', 'Study_Type_Wetzels', 'Study_Type_Wood', 'Study_Type_Worthy'])\n",
    "df_standard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exporting Data to CSV file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_standard.to_csv('data/normalise.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
